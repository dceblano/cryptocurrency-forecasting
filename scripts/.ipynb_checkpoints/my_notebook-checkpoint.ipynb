{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parquet():\n",
    "    cwd = os.getcwd()\n",
    "    print( \"Current Path:\", cwd )\n",
    "    os.chdir('../data')\n",
    "    data_dir = Path(os.getcwd() +'/parquet/')\n",
    "\n",
    "    # 2023 trip data dataframe\n",
    "    tripdata_2023_df = pd.concat(\n",
    "        pd.read_parquet(parquet_file)\n",
    "        for parquet_file in data_dir.glob('*.parquet')\n",
    "    )\n",
    "\n",
    "    return tripdata_2023_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cleanup(df):\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_timeseries_forecasting(df):\n",
    "    # Preprocess the data\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df.set_index('tpep_pickup_datetime', inplace=True)\n",
    "\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    print(numeric_columns)\n",
    "    df[numeric_columns] = df[numeric_columns].resample('1H').mean().fillna(0)\n",
    "    \n",
    "    #df = df.resample('1H').mean().fillna(0)  # Resample to hourly and fill NaN values\n",
    "\n",
    "    # Splitting data into train and test sets\n",
    "    train_data, test_data = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Define SARIMA parameters\n",
    "    #order = (2, 1, 1)  # ARIMA(p, d, q)\n",
    "    #seasonal_order = (1, 0, 1, 24)  # SARIMA(P, D, Q, m)\n",
    "    order = (1, 1, 1)  # ARIMA(p, d, q)\n",
    "    seasonal_order = (0, 1, 1, 12)  # SARIMA(P, D, Q, m)\n",
    "\n",
    "\n",
    "    # Fit SARIMA model\n",
    "    sarima_model = SARIMAX(train_data['fare_amount'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    sarima_result = sarima_model.fit()\n",
    "    sarima_result\n",
    "\n",
    "    # Make predictions\n",
    "    predicted = sarima_result.predict(start=test_data.index[0], end=test_data.index[-1], dynamic=True)\n",
    "    predicted\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(test_data['fare_amount'], predicted)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "    # Plot actual vs. predicted fares\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(test_data.index, test_data['fare_amount'], label='Actual')\n",
    "    plt.plot(test_data.index, predicted, label='Predicted', color='red')\n",
    "    plt.title('Actual vs. Predicted Fare Amount (SARIMA)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Fare Amount')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Get parquet\n",
    "    print(\"#1 Read parquet\")\n",
    "    taxi_df = get_parquet()\n",
    "    print(taxi_df.info())\n",
    "\n",
    "    # Perform cleanup\n",
    "    print(\"#2 Perform cleanup\")\n",
    "    cleaned_df = perform_cleanup(taxi_df)\n",
    "\n",
    "    # Perform time series forecasting\n",
    "    #print(\"#3 Perform time series forecasting\")\n",
    "    #perform_timeseries_forecasting(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Read parquet\n",
      "Current Path: C:\\Users\\denni\\Documents\\Lambton\\2nd term\\BDM 3014 - Introduction to AI\\project\\nyc-taxi-fare-prediction\\scripts\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38310226 entries, 0 to 3376566\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      " 19  Airport_fee            float64       \n",
      "dtypes: datetime64[us](2), float64(13), int64(4), object(1)\n",
      "memory usage: 6.0+ GB\n",
      "None\n",
      "#2 Perform cleanup\n",
      "VendorID                        0\n",
      "tpep_pickup_datetime            0\n",
      "tpep_dropoff_datetime           0\n",
      "passenger_count           1309356\n",
      "trip_distance                   0\n",
      "RatecodeID                1309356\n",
      "store_and_fwd_flag        1309356\n",
      "PULocationID                    0\n",
      "DOLocationID                    0\n",
      "payment_type                    0\n",
      "fare_amount                     0\n",
      "extra                           0\n",
      "mta_tax                         0\n",
      "tip_amount                      0\n",
      "tolls_amount                    0\n",
      "improvement_surcharge           0\n",
      "total_amount                    0\n",
      "congestion_surcharge      1309356\n",
      "airport_fee              35315203\n",
      "Airport_fee               4304379\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Path: C:\\Users\\denni\\Documents\\Lambton\\2nd term\\BDM 3014 - Introduction to AI\\project\\nyc-taxi-fare-prediction\\scripts\n"
     ]
    }
   ],
   "source": [
    " taxi_df = get_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.10</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403761</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:24:25</td>\n",
       "      <td>2023-03-31 23:40:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>163</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>12.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403762</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:24:50</td>\n",
       "      <td>2023-04-01 00:04:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>125</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>40.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403763</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:26:31</td>\n",
       "      <td>2023-03-31 23:49:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>24.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403764</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:07:51</td>\n",
       "      <td>2023-03-31 23:15:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>113</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>8.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403765</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-31 23:26:12</td>\n",
       "      <td>2023-03-31 23:31:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>13.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9384487 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1               2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2               2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3               1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4               2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "3403761         2  2023-03-31 23:24:25   2023-03-31 23:40:54              NaN   \n",
       "3403762         2  2023-03-31 23:24:50   2023-04-01 00:04:12              NaN   \n",
       "3403763         2  2023-03-31 23:26:31   2023-03-31 23:49:39              NaN   \n",
       "3403764         2  2023-03-31 23:07:51   2023-03-31 23:15:56              NaN   \n",
       "3403765         2  2023-03-31 23:26:12   2023-03-31 23:31:47              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 0.97         1.0                  N           161   \n",
       "1                 1.10         1.0                  N            43   \n",
       "2                 2.51         1.0                  N            48   \n",
       "3                 1.90         1.0                  N           138   \n",
       "4                 1.43         1.0                  N           107   \n",
       "...                ...         ...                ...           ...   \n",
       "3403761           3.16         NaN               None           163   \n",
       "3403762           6.89         NaN               None           125   \n",
       "3403763           4.01         NaN               None            50   \n",
       "3403764           1.31         NaN               None           113   \n",
       "3403765           0.88         NaN               None            41   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 141             2         9.30   1.00      0.5        0.00   \n",
       "1                 237             1         7.90   1.00      0.5        4.00   \n",
       "2                 238             1        14.90   1.00      0.5       15.00   \n",
       "3                   7             1        12.10   7.25      0.5        0.00   \n",
       "4                  79             1        11.40   1.00      0.5        3.28   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "3403761            75             0        12.13   0.00      0.5        4.23   \n",
       "3403762           198             0        40.92   0.00      0.5        8.98   \n",
       "3403763           224             0        24.02   0.00      0.5        0.00   \n",
       "3403764           158             0         8.51   0.00      0.5        3.50   \n",
       "3403765           166             0        13.51   0.00      0.5        2.25   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                 0.0                    1.0         14.30   \n",
       "1                 0.0                    1.0         16.90   \n",
       "2                 0.0                    1.0         34.90   \n",
       "3                 0.0                    1.0         20.85   \n",
       "4                 0.0                    1.0         19.68   \n",
       "...               ...                    ...           ...   \n",
       "3403761           0.0                    1.0         20.36   \n",
       "3403762           0.0                    1.0         53.90   \n",
       "3403763           0.0                    1.0         28.02   \n",
       "3403764           0.0                    1.0         16.01   \n",
       "3403765           0.0                    1.0         17.26   \n",
       "\n",
       "         congestion_surcharge  airport_fee  Airport_fee  \n",
       "0                         2.5         0.00          NaN  \n",
       "1                         2.5         0.00          NaN  \n",
       "2                         2.5         0.00          NaN  \n",
       "3                         0.0         1.25          NaN  \n",
       "4                         2.5         0.00          NaN  \n",
       "...                       ...          ...          ...  \n",
       "3403761                   NaN          NaN          NaN  \n",
       "3403762                   NaN          NaN          NaN  \n",
       "3403763                   NaN          NaN          NaN  \n",
       "3403764                   NaN          NaN          NaN  \n",
       "3403765                   NaN          NaN          NaN  \n",
       "\n",
       "[9384487 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_cleanup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mperform_cleanup\u001b[49m(taxi_df)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#new_df['fare_amount_numeric'] = pd.to_numeric(new_df['fare_amount'], errors='coerce')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#filtered_df = new_df[new_df['fare_amount_numeric'].isna()]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#filtered_df\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#print(new_df['tpep_pickup_datetime'].dtype) \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perform_cleanup' is not defined"
     ]
    }
   ],
   "source": [
    "new_df = perform_cleanup(taxi_df)\n",
    "#new_df['fare_amount_numeric'] = pd.to_numeric(new_df['fare_amount'], errors='coerce')\n",
    "\n",
    "#filtered_df = new_df[new_df['fare_amount_numeric'].isna()]\n",
    "#filtered_df\n",
    "\n",
    "#print(new_df['tpep_pickup_datetime'].dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'passenger_count', 'trip_distance', 'RatecodeID',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'airport_fee', 'Airport_fee'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.53 GiB for an array with shape (9, 9, 7507589) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_smoother.pyx:988\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.allocate_arrays\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.53 GiB for an array with shape (9, 9, 7507589) and data type float64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'statsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.reset_filter_method'\n",
      "Traceback (most recent call last):\n",
      "  File \"statsmodels\\tsa\\statespace\\_kalman_smoother.pyx\", line 988, in statsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.allocate_arrays\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 4.53 GiB for an array with shape (9, 9, 7507589) and data type float64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Memoryview is not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#taxi_df = get_parquet()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mperform_timeseries_forecasting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaxi_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m, in \u001b[0;36mperform_timeseries_forecasting\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Fit SARIMA model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m sarima_model \u001b[38;5;241m=\u001b[39m SARIMAX(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m], order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order, enforce_stationarity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, enforce_invertibility\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 24\u001b[0m sarima_result \u001b[38;5;241m=\u001b[39m \u001b[43msarima_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m sarima_result\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
      "File \u001b[1;32mD:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:728\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth\n\u001b[1;32m--> 728\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlefit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincludes_fixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m           \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_kwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m res\u001b[38;5;241m.\u001b[39mmlefit \u001b[38;5;241m=\u001b[39m mlefit\n\u001b[0;32m    732\u001b[0m res\u001b[38;5;241m.\u001b[39mmle_retvals \u001b[38;5;241m=\u001b[39m mlefit\u001b[38;5;241m.\u001b[39mmle_retvals\n",
      "File \u001b[1;32mD:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:886\u001b[0m, in \u001b[0;36mMLEModel.smooth\u001b[1;34m(self, params, transformed, includes_fixed, complex_step, cov_type, cov_kwds, return_ssm, results_class, results_wrapper_class, **kwargs)\u001b[0m\n\u001b[0;32m    883\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Get the state space output\u001b[39;00m\n\u001b[1;32m--> 886\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;66;03m# Wrap in a results object\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_results(params, result, return_ssm, cov_type,\n\u001b[0;32m    890\u001b[0m                           cov_kwds, results_class,\n\u001b[0;32m    891\u001b[0m                           results_wrapper_class)\n",
      "File \u001b[1;32mD:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_smoother.py:419\u001b[0m, in \u001b[0;36mKalmanSmoother.smooth\u001b[1;34m(self, smoother_output, smooth_method, results, run_filter, prefix, complex_step, update_representation, update_filter, update_smoother, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m smoother_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    418\u001b[0m     smoother_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmoother_output\n\u001b[1;32m--> 419\u001b[0m smoother \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smooth\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmoother_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# Update the results\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update_smoother:\n",
      "File \u001b[1;32mD:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_smoother.py:369\u001b[0m, in \u001b[0;36mKalmanSmoother._smooth\u001b[1;34m(self, smoother_output, smooth_method, prefix, complex_step, results, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m smoother \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_smoothers[prefix]\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Run the smoother\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m \u001b[43msmoother\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m smoother\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_smoother.pyx:1214\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_smoother.pyx:1239\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.__next__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_smoother.pyx:1429\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.initialize_smoother_object_pointers\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Memoryview is not initialized"
     ]
    }
   ],
   "source": [
    "#taxi_df = get_parquet()\n",
    "perform_timeseries_forecasting(taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2023-01-01 00:32:10\n",
       "1         2023-01-01 00:55:08\n",
       "2         2023-01-01 00:25:04\n",
       "3         2023-01-01 00:03:48\n",
       "4         2023-01-01 00:10:29\n",
       "                  ...        \n",
       "3403761   2023-03-31 23:24:25\n",
       "3403762   2023-03-31 23:24:50\n",
       "3403763   2023-03-31 23:26:31\n",
       "3403764   2023-03-31 23:07:51\n",
       "3403765   2023-03-31 23:26:12\n",
       "Name: tpep_pickup_datetime, Length: 9384487, dtype: datetime64[us]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_df['tpep_pickup_datetime'].dtype\n",
    "#taxi_df[taxi_df['fare_amount']=='NNNNN']\n",
    "#taxi_df\n",
    "taxi_df['tpep_pickup_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column \"store_and_fwd_flag\" contains non-numeric values:\n",
      "0             N\n",
      "1             N\n",
      "2             N\n",
      "3             N\n",
      "4             N\n",
      "           ... \n",
      "3376562    None\n",
      "3376563    None\n",
      "3376564    None\n",
      "3376565    None\n",
      "3376566    None\n",
      "Name: store_and_fwd_flag, Length: 38310226, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Check data types of columns\n",
    "column_data_types = taxi_df.dtypes\n",
    "\n",
    "# Filter columns with non-numeric data types (e.g., object, string)\n",
    "non_numeric_columns = column_data_types[column_data_types == 'object'].index\n",
    "\n",
    "# Check for non-numeric values in non-numeric columns\n",
    "for col in non_numeric_columns:\n",
    "    non_numeric_values = taxi_df[col].loc[~pd.to_numeric(taxi_df[col], errors='coerce').notna()]\n",
    "    if not non_numeric_values.empty:\n",
    "        print(f'Column \"{col}\" contains non-numeric values:')\n",
    "        print(non_numeric_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
